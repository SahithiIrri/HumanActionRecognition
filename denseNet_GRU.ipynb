{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edab97ee-b5a1-4535-ba41-45345ad48ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GRU, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f93a66cc-dd4e-4305-82b0-af99ba261610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_videos(video_path, sequence_length=20):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_indices = np.linspace(0, total_frames - 1, sequence_length, dtype=int)\n",
    "\n",
    "    for i in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (80, 80)) / 255.0  # Resize & normalize\n",
    "            frames.append(frame)\n",
    "    cap.release()\n",
    "    return np.array(frames) if len(frames) == sequence_length else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "415d0e24-8e2c-4a34-914b-a22981935deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_path):\n",
    "    X, y = [], []\n",
    "    for label in os.listdir(dataset_path):\n",
    "        action_path = os.path.join(dataset_path, label)\n",
    "        if os.path.isdir(action_path):\n",
    "            for video_file in os.listdir(action_path):\n",
    "                video_path = os.path.join(action_path, video_file)\n",
    "                frames = load_videos(video_path)\n",
    "                if frames is not None:\n",
    "                    X.append(frames)\n",
    "                    y.append(label)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    y = to_categorical(y)\n",
    "    return np.array(X), np.array(y), le.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5dd2ed1-929b-4248-949c-7f5bcc83c9bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.93 MiB for an array with shape (20, 80, 80, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msahit\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mproject_dataset-20250201T092348Z-001\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mproject_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m X, y, class_names \u001b[38;5;241m=\u001b[39m prepare_dataset(dataset_path)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train-test split\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36mprepare_dataset\u001b[1;34m(dataset_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(action_path):\n\u001b[0;32m      7\u001b[0m     video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(action_path, video_file)\n\u001b[1;32m----> 8\u001b[0m     frames \u001b[38;5;241m=\u001b[39m load_videos(video_path)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m         X\u001b[38;5;241m.\u001b[39mappend(frames)\n",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m, in \u001b[0;36mload_videos\u001b[1;34m(video_path, sequence_length)\u001b[0m\n\u001b[0;32m     12\u001b[0m         frames\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[0;32m     13\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(frames) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(frames) \u001b[38;5;241m==\u001b[39m sequence_length \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.93 MiB for an array with shape (20, 80, 80, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "dataset_path = r\"C:\\Users\\sahit\\Downloads\\project_dataset-20250201T092348Z-001\\project_dataset\"\n",
    "X, y, class_names = prepare_dataset(dataset_path)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7f760-7e3f-4aa1-a963-938d2febbfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.applications import DenseNet121  # Or a different DenseNet version\n",
    "\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(80, 80, 3))\n",
    "base_model.trainable = False  # Freeze weights\n",
    "\n",
    "\n",
    "base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Optionally, you can summarize the model\n",
    "base_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f511a-b64a-4d37-8bf7-548b2242c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(frames):\n",
    "    features = []\n",
    "    for frame in frames:\n",
    "        feature_map = base_model.predict(np.expand_dims(frame, axis=0))  # Shape: (1, 3, 3, 2048)\n",
    "        pooled_features = GlobalAveragePooling2D()(feature_map)  # Shape: (1, 2048)\n",
    "        features.append(pooled_features.numpy().flatten())  # Convert tensor to NumPy array\n",
    "    return np.array(features)  # Shape: (20, 2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476ef69-995f-4a86-94dd-91b1e3611947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array([extract_features(video) for video in tqdm(X_train, desc=\"Processing training videos\")])\n",
    "X_test = np.array([extract_features(video) for video in tqdm(X_test, desc=\"Processing testing videos\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f2276-1fce-49ac-b50b-ca291eee0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dropout, Dense, Input\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(20, 1024)),  # Explicitly define the input shape\n",
    "    GRU(256, return_sequences=False),  # No need for input_shape here\n",
    "    Dropout(0.5),\n",
    "    Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Optionally, you can summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948b8aa-c017-483e-9184-7f72a75dbc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ad392f-2135-4c20-877f-a1580e117adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"gru_model.keras\")  # Saves in the new format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a233f4-a433-48b2-97bc-25eed295e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b7f7b-53ca-4108-8ee2-0a10383f45b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, ac = model.evaluate(X_train, y_train)\n",
    "print(f\"Train Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a2b5a-0b0e-4198-9724-82d84ad401b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class TrainingPlotCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epoch_data = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Capture metrics at the end of each epoch\n",
    "        self.epoch_data.append({\n",
    "            'accuracy': logs.get('accuracy') * 100,\n",
    "            'loss': logs.get('loss'),\n",
    "            'val_accuracy': logs.get('val_accuracy') * 100,\n",
    "            'val_loss': logs.get('val_loss')\n",
    "        })\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"Plot the captured metrics after training.\"\"\"\n",
    "        epochs = range(1, len(self.epoch_data) + 1)\n",
    "        train_acc = [data['accuracy'] for data in self.epoch_data]\n",
    "        train_loss = [data['loss'] for data in self.epoch_data]\n",
    "        val_acc = [data['val_accuracy'] for data in self.epoch_data]\n",
    "        val_loss = [data['val_loss'] for data in self.epoch_data]\n",
    "\n",
    "        # Set plot style\n",
    "        plt.style.use('ggplot')  # Using a built-in style that works\n",
    "\n",
    "        # Create the plot with two subplots: Accuracy and Loss\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "        # Accuracy plot\n",
    "        ax[0].plot(epochs, train_acc, label='Train Accuracy', color='royalblue', marker='o', markersize=6, linestyle='-', linewidth=2)\n",
    "        ax[0].plot(epochs, val_acc, label='Validation Accuracy', color='darkorange', marker='s', markersize=6, linestyle='--', linewidth=2)\n",
    "        ax[0].set_title('Model Accuracy', fontsize=14)\n",
    "        ax[0].set_xlabel('Epochs', fontsize=12)\n",
    "        ax[0].set_ylabel('Accuracy', fontsize=12)\n",
    "        ax[0].legend()\n",
    "        ax[0].grid(True)\n",
    "\n",
    "        # Loss plot\n",
    "        ax[1].plot(epochs, train_loss, label='Train Loss', color='green', marker='^', markersize=6, linestyle='-', linewidth=2)\n",
    "        ax[1].plot(epochs, val_loss, label='Validation Loss', color='red', marker='x', markersize=6, linestyle='--', linewidth=2)\n",
    "        ax[1].set_title('Model Loss', fontsize=14)\n",
    "        ax[1].set_xlabel('Epochs', fontsize=12)\n",
    "        ax[1].set_ylabel('Loss', fontsize=12)\n",
    "        ax[1].legend()\n",
    "        ax[1].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you are training a Keras model like this:\n",
    "\n",
    "# Initialize the custom callback\n",
    "plot_callback = TrainingPlotCallback()\n",
    "\n",
    "# Train the model and pass the callback to capture epoch data\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32, callbacks=[plot_callback])\n",
    "\n",
    "# After training is done, plot the graphs\n",
    "plot_callback.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30e059-fb10-46ce-a473-bb93de33dc0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.applications import DenseNet121  # Or a different DenseNet version\n",
    "\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(80, 80, 3))\n",
    "base_model.trainable = False  # Freeze weights\n",
    "global_avg_pool = GlobalAveragePooling2D()\n",
    "\n",
    "# Class names (Make sure it's the same as during training)\n",
    "class_names = [\"Sit down\",\"Fencing\",\"Basketball\",\"Billiards\",\"Sitting\",\"ThrowDiscus\",\n",
    "               \"BaseballPitch\",\"Walking\",\"Standing\",\"Stand up\",\"Lying Down\",\n",
    "               \"Fall Down\",\"HorseRiding\",\"Drumming\",\"CleanAndJerk\",\n",
    "               \"Biking\",\"BenchPress\"]  # Change this to match your dataset\n",
    "\n",
    "# Function to process a single video\n",
    "def predict_video(video_path, sequence_length=20):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    while len(frames) < sequence_length:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Stop if video ends\n",
    "\n",
    "        frame = cv2.resize(frame, (80, 80)) / 255.0  # Resize & normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        print(\"Error: No frames found in video!\")\n",
    "        return None\n",
    "\n",
    "    # If the video is too short, repeat the last frame\n",
    "    while len(frames) < sequence_length:\n",
    "        frames.append(frames[-1])\n",
    "\n",
    "    frames = np.array(frames[:sequence_length])\n",
    "\n",
    "    features = np.array([\n",
    "        global_avg_pool(base_model.predict(np.expand_dims(frame, axis=0))).numpy().flatten()\n",
    "        for frame in frames\n",
    "    ])  # Shape: (20, 2048)\n",
    "\n",
    "    features = np.expand_dims(features, axis=0)  # Shape: (1, 20, 2048) for model input\n",
    "\n",
    "    # Predict action\n",
    "    predictions = model.predict(features)\n",
    "    predicted_class = np.argmax(predictions)\n",
    "\n",
    "    print(f\"Predicted Action: {class_names[predicted_class]}\")\n",
    "    return class_names[predicted_class]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b8371-d226-4f11-8616-28c174e4ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a video file\n",
    "video_file = r\"C:\\Users\\sahit\\Downloads\\project_dataset-20250201T092348Z-001\\project_dataset\\Drumming\\v_Drumming_g24_c06.avi\"# Change to your test video\n",
    "predicted_action = predict_video(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef8d80b-0c19-4dfc-83fd-acd9175c0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#excess code\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "# Load Pretrained DenseNet121 for Feature Extraction\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(80, 80, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "global_avg_pool = GlobalAveragePooling2D()\n",
    "\n",
    "# Load the trained GRU classification model\n",
    "model = load_model(\"gru_model.keras\")  # Ensure this file exists\n",
    "\n",
    "# Define class names (Ensure this matches the model's training labels)\n",
    "class_names = [\"Sit down\", \"Fencing\", \"Basketball\", \"Billiards\", \"Sitting\", \"ThrowDiscus\",\n",
    "               \"BaseballPitch\", \"Walking\", \"Standing\", \"Stand up\", \"Lying Down\",\n",
    "               \"Fall Down\", \"HorseRiding\", \"Drumming\", \"CleanAndJerk\",\n",
    "               \"Biking\", \"BenchPress\"]\n",
    "\n",
    "# Function to process a video and predict the action\n",
    "def predict_video(video_path, sequence_length=20):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    while len(frames) < sequence_length:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Stop if the video ends\n",
    "\n",
    "        frame = cv2.resize(frame, (80, 80)) / 255.0  # Resize & normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        print(\"Error: No frames found in video!\")\n",
    "        return None\n",
    "\n",
    "    # Pad sequence if it's too short\n",
    "    while len(frames) < sequence_length:\n",
    "        frames.append(frames[-1])  # Repeat the last frame\n",
    "\n",
    "    frames = np.array(frames[:sequence_length])  # Convert to NumPy array\n",
    "\n",
    "    # **Efficient Feature Extraction using Batch Processing**\n",
    "    features = base_model.predict(frames, batch_size=sequence_length)  # Shape: (20, 2, 2, 1024)\n",
    "    features = np.array([global_avg_pool(feature[np.newaxis, ...]).numpy().flatten() for feature in features])  \n",
    "    features = np.expand_dims(features, axis=0)  # Shape: (1, 20, 1024)\n",
    "\n",
    "    # Predict Action using the GRU Model\n",
    "    predictions = model.predict(features)\n",
    "    predicted_class = np.argmax(predictions)\n",
    "\n",
    "    print(f\"Predicted Action: {class_names[predicted_class]}\")\n",
    "    return class_names[predicted_class]\n",
    "\n",
    "# Example Usage\n",
    "# predicted_action = predict_video(\"example_video.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10492fc9-90e8-4246-a7d4-d43e13568ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
